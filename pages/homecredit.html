<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Home Credit - Credit Risk Model Stability</title>

    <!-- MathJax for LaTeX rendering -->
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Prism.js CSS for syntax highlighting -->
    <link href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css" rel="stylesheet" />
    <!-- Prism.js core library -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
    <!-- Prism.js Python language support -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-python.min.js"></script>
    <!-- Prism.js LaTeX language support (for equations in code blocks if any) -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-latex.min.js"></script>

    <style>
        html {
            scroll-behavior: smooth; /* Smooth scrolling for anchor links */
        }
        body {
            font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
            color: #333;
            margin: 0;
            padding: 0;
            background-color: #f8f8f8; /* Subtle paper-like background */
        }
        .back-to-main {
            position: absolute;
            top: 1rem;
            right: 2rem;
            z-index: 1000;
        }
        .back-to-main a {
            color: #0056b3;
            text-decoration: none;
            font-size: 0.9em;
        }
        .back-to-main a:hover {
            text-decoration: underline;
        }
        .container {
            max-width: 1100px; /* Adjusted to accommodate wider grid, overall document width */
            margin: 0 auto; /* Center the content */
            padding: 2.5rem 1.2rem;
            line-height: 1.75; /* Increase line height for comfortable reading */
        }

        h1 {
            font-size: 2.2rem;
            margin-top: 0;
            margin-bottom: 0.5em;
            color: #222;
        }
        .author-info {
            font-size: 0.9em;
            color: #666;
            display: block;
            margin-bottom: 2em;
        }

        .site-navigation {
            position: sticky;
            top: 0;
            background: rgba(248, 248, 248, 0.95);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid #e0e0e0;
            margin: 1rem auto 2rem;
            padding: 0.8rem 0;
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 1.5em;
            z-index: 100;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
            transition: all 0.3s ease;
        }
        .site-navigation a {
            color: #0056b3;
            text-decoration: none;
            padding: 0.4em 0.8em;
            font-size: 0.9em;
            font-weight: 500;
            white-space: nowrap;
            border-radius: 4px;
            transition: all 0.2s ease;
            position: relative;
        }
        .site-navigation a:hover {
            /* No hover effects - clean and simple */
        }
        .site-navigation a.active {
            /* No active state styling - clean and simple */
        }

        h2 {
            font-size: 1.6rem;
            margin-top: 2.5rem;
            margin-bottom: 1em;
            color: #222;
            border-bottom: 1px solid #eee;
            padding-bottom: 0.5em;
        }
        h3 {
            font-size: 1.4rem;
            margin-top: 2rem;
            margin-bottom: 1em;
            color: #222;
        }
        p {
            margin-bottom: 1em;
            font-size: 1.05rem;
        }
        ul {
            margin-bottom: 1em;
            padding-left: 1.5em;
        }
        li {
            margin-bottom: 0.5em;
        }

        /* Code Block Styles */
        .code-module {
            max-width: 100%; /* Adjust to fit within the grid column */
            margin: 1.5em auto; /* Centered, and align with the grid */
            background-color: #f9f9f9;
            padding: 1.2em;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .code-title {
            font-weight: bold;
            margin-bottom: 0.8em;
            font-size: 1em;
            color: #333;
            text-align: center;
        }
        pre {
            margin: 0;
            max-height: 200px;
            overflow-y: auto;
            white-space: pre-wrap;
            word-break: break-all;
        }
        pre code {
            display: block;
            padding: 0.5em;
            font-size: 0.9em;
            line-height: 1.5;
        }

        /* Responsive Adjustments */
        @media (max-width: 768px) {
            .container {
                padding: 1.5rem 1rem;
            }
            h1 {
                font-size: 1.8rem;
            }
            h2 {
                font-size: 1.4rem;
            }
            p {
                font-size: 1rem;
            }
            .site-navigation {
                flex-direction: column; /* Stack links vertically on smaller screens */
                align-items: center; /* Center stacked links */
                gap: 0.5em;
            }
            .site-navigation a {
                padding: 0.1em 0;
            }
        }
    </style>
</head>
<body>
    <div class="back-to-main">
        <a href="../index.html">Back to Main</a>
    </div>
    <div class="container">
        <h1 id="compTitle">Home Credit - Credit Risk Model Stability (Kaggle 2023)</h1>
        <nav class="site-navigation">
            <a href="#project-overview">Project Overview</a>
            <a href="#dataset-analysis">Dataset Analysis</a>
            <a href="#methodology">Methodology</a>
            <a href="#key-equations">Key Equations</a>
            <a href="#implementation">Implementation</a>
            <a href="#results-insights">Results & Insights</a>
        </nav>
        <span class="author-info">Silver Medal (Top 1.2%) Â· Metric: Custom Gini Stability Metric</span>

        <!-- 2. Project Overview -->
        <h2 id="project-overview">Project Overview</h2>
        <p>This competition, hosted by Home Credit, a global consumer finance provider, focused on predicting customer loan defaults. The primary objective was to develop a machine learning model capable of accurately assessing default risk, particularly for individuals with limited or no credit history. A key challenge and unique aspect of this competition was the emphasis on <b>model stability</b> over time, reflecting the dynamic nature of customer behavior and the need for robust, long-term solutions in real-world credit scoring. The competition title, "Credit Risk Model Stability," highlighted this crucial requirement, necessitating a balance between predictive performance and consistency over varying time periods.</p>
        
        <h3>Evaluation Metric</h3>
        <p>The competition utilized a custom <b>Gini Stability Metric</b> to evaluate submissions, moving beyond just predictive accuracy to include model consistency over time. The metric calculation involved several components:</p>
        <ul>
          <li><b>Gini Score per Week:</b> The Gini coefficient was calculated for predictions corresponding to each <code>WEEK_NUM</code>. The Gini coefficient is derived from AUC (Area Under the ROC Curve) as: <code>gini = 2 * AUC - 1</code></li>
          <li><b>Falling Rate Penalty:</b> A linear regression (<code>a*x + b</code>) was performed on the weekly Gini scores. A penalty was applied based on the slope <code>a</code>, specifically <code>min(0, a)</code>, to penalize models whose predictive power degraded over time. The coefficient for this penalty was notably high (88.0), making it a dominant factor.</li>
          <li><b>Variability Penalty:</b> The standard deviation of the residuals from the weekly Gini linear regression was calculated, and a penalty was applied for high variability, though this component was relatively minor compared to the falling rate penalty.</li>
          <li><b>Overall Stability Metric:</b> The final score was computed as: <code>stability_metric = mean(gini) + 88.0 * min(0, a) - 0.5 * std(residuals)</code></li>
        </ul>
        <p>This metric design meant that simply achieving high AUC was insufficient; models also needed to demonstrate consistent performance across different time segments of the test data.</p>

        <!-- 3. Dataset Analysis -->
        <h2 id="dataset-analysis">Dataset Analysis</h2>
        <p>The dataset comprised internal and external customer information, with the goal of predicting default status. It contained time-series behavioral data, with each <code>case_id</code> (customer) having multiple entries over different <code>WEEK_NUM</code> periods. Features were anonymized but broadly categorized by their suffixes:</p>
        <ul>
          <li><b>P / A:</b> Numerical features, likely representing proportions or amounts</li>
          <li><b>D:</b> Date-related features</li>
          <li><b>M:</b> Categorical/string features</li>
          <li><b>T / L:</b> Unspecified transformations or other types of features</li>
        </ul>
        <p>Key identifiers included <code>case_id</code> and <code>WEEK_NUM</code>, essential for handling the time-series nature of the data.</p>

        <!-- 4. Methodology -->
        <h2 id="methodology">Methodology</h2>
        <p>Our approach focused on robust feature engineering, powerful gradient boosting models, and a strategic "metric hack" to optimize for the unique evaluation criterion.</p>
        
        <h3>4.1 Feature Engineering</h3>
        <p>The feature engineering pipeline was designed to transform raw time-series data into aggregated, informative features at the <code>case_id</code> level.</p>
        <ul>
          <li><b>Data Type Conversion:</b> Raw predictor variables were cast to appropriate data types based on their suffixes and known identifiers. For example, <code>P</code> and <code>A</code> features were converted to <code>Float64</code>, <code>D</code> features to <code>Date</code>, and <code>M</code> features to <code>String</code>.</li>
          <li><b>Date Handling:</b> Date features were transformed into numerical values representing the difference in days from <code>date_decision</code>, consolidating temporal information.</li>
          <li><b>Feature Filtering:</b> To manage dimensionality and noise, columns with high missingness (over 70% nulls) were removed. Additionally, string columns with either no variance (single unique value) or excessively high cardinality (over 200 unique values) were dropped.</li>
          <li><b>Aggregations:</b> For each <code>case_id</code>, a comprehensive set of aggregated features was generated by grouping the time-series data:
            <ul>
              <li><b>Numerical Features (P, A):</b> Calculated <code>max</code>, <code>last</code>, <code>mean</code>, <code>median</code>, and <code>variance</code></li>
              <li><b>Date Features (D):</b> Calculated <code>max</code>, <code>last</code>, <code>mean</code>, and <code>median</code></li>
              <li><b>Categorical/String Features (M, T, L):</b> Calculated <code>max</code> and <code>last</code></li>
            </ul>
          </li>
        </ul>
        
        <h3>4.2 Model Building</h3>
        <ul>
          <li><b>Model Selection:</b> LightGBM and CatBoost, both powerful Gradient Boosting algorithms, were chosen for their efficiency and performance.</li>
          <li><b>Cross-Validation:</b> A 5-fold cross-validation strategy was employed to ensure robust model evaluation and generalization.</li>
          <li><b>Ensembling:</b> A voting ensemble method was used, averaging the predictions from the multiple trained models (10 models in total from 5-fold LightGBM and CatBoost) to improve stability and accuracy.</li>
          <li><b>Deployment Strategy:</b> To optimize submission times (which could exceed 10 hours), models were trained locally and then loaded for online inference, streamlining the hyperparameter tuning and submission process.</li>
        </ul>
        
        <h3>4.3 Metric Hack Method</h3>
        <p>A critical discovery during the competition was the significant impact of the "falling rate" penalty (<code>min(0, a)</code>) in the evaluation metric. This led to the development of a strategic post-processing "hack" to mitigate this penalty, especially for the private leaderboard.</p>
        <ul>
          <li><b>Understanding the Penalty:</b> The metric heavily penalized models whose Gini scores decreased over <code>WEEK_NUM</code>, making model stability crucial.</li>
          <li><b>Targeted Adjustment:</b> The team identified <code>max_pmts_year_507T</code> (maximum payment year for closed credit contracts) as a key feature to help reconstruct the test set timeline.</li>
          <li><b>Prediction Manipulation:</b> A specific post-processing step was applied where predictions below a certain threshold (e.g., 0.96) were manually reduced by a fixed amount (e.g., 0.07), then clipped at zero. This was designed to subtly shift prediction scores in a way that improved the stability component of the metric, particularly for time segments that might otherwise lead to a negative Gini slope.</li>
          <li><b>Public vs. Private Success:</b> While other high-scoring public hacks (e.g., blanket subtraction of 0.05 for predictions < 0.96) led to severe overfitting on the private dataset, our method, which targeted adjustments based on time, proved resilient. This suggests the private dataset had a time-based split, which our strategic adjustment handled effectively.</li>
        </ul>

        <!-- 5. Key Equations -->
        <h2 id="key-equations">Key Equations</h2>
        <p>The evaluation utilized a custom Gini Stability Metric, which incorporated Gini coefficients calculated per <code>WEEK_NUM</code>, the trend of these Gini scores, and their variability.</p>
        <p>The Gini coefficient for each <code>WEEK_NUM</code> is defined as:
        $$\mathrm{gini} = 2 \times \mathrm{AUC} - 1$$
        <p>The Area Under the Curve (AUC) is defined as:</p>
        <p>$$\mathrm{AUC}  \;=\; \int_{0}^{1} \mathrm{TPR}\!\bigl(\mathrm{FPR}^{-1}(t)\bigr)\,dt$$</p>
        <p>The overall stability metric calculation would combine these Gini values over time, for instance:</p>
        <p>$$\text{Stability Metric} = f(\text{Gini}_{WEEK_1}, \text{Gini}_{WEEK_2}, \dots, \text{Gini}_{WEEK_N})$$</p>
        <p>This could involve assessing the mean Gini, standard deviation of Gini, and the slope of Gini over weeks.</p>

        <!-- 6. Implementation -->
        <h2 id="implementation">Implementation (Python)</h2>
        <p>The solution leveraged <code>Polars</code> for efficient data manipulation and <code>LightGBM</code> for modeling. The key feature engineering and a demonstration of the "hack" can be observed in the provided notebook snippets.</p>
        
        <h3>pb-0.60652-pv-0.56411.ipynb: Feature Engineering and Data Preparation</h3>
        <p>This notebook outlines the core data processing and feature generation steps using <code>polars</code> for efficiency.</p>
        <div class="code-module">
            <div class="code-title">Python Code Example</div>
            <pre><code class="language-python">
import joblib
from pathlib import Path
import gc
from glob import glob
import numpy as np
import pandas as pd
import polars as pl
from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.metrics import roc_auc_score
import lightgbm as lgb

import warnings
warnings.filterwarnings('ignore')

ROOT = '/kaggle/input/home-credit-credit-risk-model-stability'

class Pipeline:

    def set_table_dtypes(df):
        for col in df.columns:
            if col in ["case_id", "WEEK_NUM", "num_group1", "num_group2"]:
                df = df.with_columns(pl.col(col).cast(pl.Int64))
            elif col in ["date_decision"]:
                df = df.with_columns(pl.col(col).cast(pl.Date))
            elif col[-1] in ("P", "A"):
                df = df.with_columns(pl.col(col).cast(pl.Float64))
            elif col[-1] in ("M",):
                df = df.with_columns(pl.col(col).cast(pl.String))
            elif col[-1] in ("D",):
                df = df.with_columns(pl.col(col).cast(pl.Date))
        return df

    def handle_dates(df):
        for col in df.columns:
            if col[-1] in ("D",):
                df = df.with_columns(pl.col(col) - pl.col("date_decision"))
                df = df.with_columns(pl.col(col).dt.total_days())
        df = df.drop("date_decision", "MONTH")
        return df

    def filter_cols(df):
        for col in df.columns:
            if col not in ["target", "case_id", "WEEK_NUM"]:
                isnull = df[col].is_null().mean()
                if isnull > 0.7:
                    df = df.drop(col)

        for col in df.columns:
            if (col not in ["target", "case_id", "WEEK_NUM"]) & (df[col].dtype == pl.String):
                freq = df[col].n_unique()
                if (freq == 1) | (freq > 200):
                    df = df.drop(col)

        return df


class Aggregator:
    def num_expr(df):
        cols = [col for col in df.columns if col[-1] in ("P", "A")]
        expr_max = [pl.max(col).alias(f"max_{col}") for col in cols]
        expr_last = [pl.last(col).alias(f"last_{col}") for col in cols]
        expr_mean = [pl.mean(col).alias(f"mean_{col}") for col in cols]
        expr_median = [pl.median(col).alias(f"median_{col}") for col in cols]
        expr_var = [pl.var(col).alias(f"var_{col}") for col in cols]
        return expr_max + expr_last + expr_mean

    def date_expr(df):
        cols = [col for col in df.columns if col[-1] in ("D")]
        expr_max = [pl.max(col).alias(f"max_{col}") for col in cols]
        expr_last = [pl.last(col).alias(f"last_{col}") for col in cols]
        expr_mean = [pl.mean(col).alias(f"mean_{col}") for col in cols]
        expr_median = [pl.median(col).alias(f"median_{col}") for col in cols]
        return expr_max + expr_last + expr_mean

    def str_expr(df):
        cols = [col for col in df.columns if col[-1] in ("M",)]
        expr_max = [pl.max(col).alias(f"max_{col}") for col in cols]
        expr_last = [pl.last(col).alias(f"last_{col}") for col in cols]
        return expr_max + expr_last

    def other_expr(df):
        cols = [col for col in df.columns if col[-1] in ("T", "L")]
        expr_max = [pl.max(col).alias(f"max_{col}") for col in cols]
        expr_last = [pl.last(col).alias(f"last_{col}") for col in cols]
        return expr_max + expr_last
            </code></pre>
        </div>

        <h3>pb-0.64334-pv-0.51507.ipynb: Ensemble and Metric Hack</h3>
        <p>This notebook demonstrates the final ensemble and the crucial post-processing "hack" applied to the predictions before submission.</p>
        <div class="code-module">
            <div class="code-title">Python Code Example</div>
            <pre><code class="language-python">
import sys
from pathlib import Path
import subprocess
import os
import gc
from glob import glob

import numpy as np
import pandas as pd
import polars as pl
from datetime import datetime
import seaborn as sns
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold
from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.metrics import roc_auc_score
import lightgbm as lgb

# --- Metric Hack Application ---
df_subm = pd.read_csv("/kaggle/working/sub.csv")
df_subm = df_subm.set_index("case_id")

# Apply the specific "hack": reduce predictions less than 0.96 by 0.07, clipped at 0
condition = y_pred_placeholder < 0.96
df_subm.loc[condition, 'score'] = (df_subm.loc[condition, 'score'] - 0.07).clip(0)

df_subm.to_csv("submission.csv")
            </code></pre>
        </div>

        <!-- 7. Results & Insights -->
        <h2 id="results-insights">Results & Insights</h2>
        <p>Our solution achieved a <b>Silver Medal</b> in the Home Credit - Credit Risk Model Stability competition, placing in the top 1.2% of participants. This strong performance was primarily attributed to:</p>
        <ul>
          <li><b>Deep understanding of the evaluation metric:</b> Recognizing the heavy penalty on declining Gini scores (negative slope) was crucial.</li>
          <li><b>Effective Metric Hack:</b> The team's carefully designed post-processing strategy, which involved selectively adjusting predictions based on temporal insights (e.g., using <code>max_pmts_year_507T</code>), proved highly effective. Unlike simpler hacks that led to overfitting on the public leaderboard, our method maintained stability and performed exceptionally well on the private dataset.</li>
          <li><b>Robust Feature Engineering:</b> The comprehensive aggregation of time-series data into rich, informative features provided a strong foundation for the models.</li>
          <li><b>Strategic Model Ensembling:</b> Combining the strengths of LightGBM and CatBoost through a 5-fold cross-validation and voting mechanism enhanced overall predictive power and generalization.</li>
        </ul>
        <p>The success on the private leaderboard, despite a public leaderboard shake-up caused by simpler, overfit hacks, underscored the importance of designing solutions that are robust to shifts in data distribution, particularly in time-series prediction tasks.</p>
    </div>
    
    <script>
        // Smooth scrolling and active navigation highlighting
        document.addEventListener('DOMContentLoaded', function() {
            const navLinks = document.querySelectorAll('.site-navigation a');
            const sections = document.querySelectorAll('h2[id]');
            
            // Function to update active navigation link
            function updateActiveNav() {
                let current = '';
                const scrollPos = window.scrollY + 100; // offset for sticky nav
                
                sections.forEach(section => {
                    const sectionTop = section.offsetTop;
                    const sectionHeight = section.offsetHeight;
                    
                    if (scrollPos >= sectionTop && scrollPos < sectionTop + sectionHeight) {
                        current = section.getAttribute('id');
                    }
                });
                
                navLinks.forEach(link => {
                    link.classList.remove('active');
                    if (link.getAttribute('href') === `#${current}`) {
                        link.classList.add('active');
                    }
                });
            }
            
            // Update active nav on scroll
            window.addEventListener('scroll', updateActiveNav);
            
            // Smooth scrolling for navigation links
            navLinks.forEach(link => {
                link.addEventListener('click', function(e) {
                    e.preventDefault();
                    const targetId = this.getAttribute('href').substring(1);
                    const targetSection = document.getElementById(targetId);
                    
                    if (targetSection) {
                        const offsetTop = targetSection.offsetTop - 80; // account for sticky nav
                        window.scrollTo({
                            top: offsetTop,
                            behavior: 'smooth'
                        });
                    }
                });
            });
            
            // Initial active nav update
            updateActiveNav();
        });
    </script>
<script id="dhws-dataInjector" src="../public/dhws-data-injector.js"></script>
</body>
</html> 